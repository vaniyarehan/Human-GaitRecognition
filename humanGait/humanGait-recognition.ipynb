{
 "cells": [
  {
   "cell_type": "code",
   "execution_count": 1,
   "id": "7fd9d8b9",
   "metadata": {
    "execution": {
     "iopub.execute_input": "2025-04-27T00:52:44.572598Z",
     "iopub.status.busy": "2025-04-27T00:52:44.572195Z",
     "iopub.status.idle": "2025-04-27T02:59:01.559966Z",
     "shell.execute_reply": "2025-04-27T02:59:01.555364Z"
    },
    "papermill": {
     "duration": 7577.015696,
     "end_time": "2025-04-27T02:59:01.583945",
     "exception": false,
     "start_time": "2025-04-27T00:52:44.568249",
     "status": "completed"
    },
    "tags": []
   },
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Loading subset of CASIA-B dataset...\n",
      "Extracting deep features using ResNet101...\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "Downloading: \"https://download.pytorch.org/models/resnet101-63fe2227.pth\" to /root/.cache/torch/hub/checkpoints/resnet101-63fe2227.pth\n",
      "100%|‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà| 171M/171M [00:01<00:00, 168MB/s]\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Selecting features using kurtosis...\n",
      "Fusing features using correlation...\n",
      "Training One-against-All SVM...\n",
      "Classification Report:\n",
      "              precision    recall  f1-score   support\n",
      "\n",
      "           0       0.77      0.73      0.75       337\n",
      "           1       0.80      0.78      0.79       313\n",
      "           2       0.69      0.69      0.69       318\n",
      "           3       0.72      0.69      0.71       331\n",
      "           4       0.82      0.92      0.87       309\n",
      "           5       0.65      0.60      0.63       341\n",
      "           6       0.85      0.83      0.84       320\n",
      "           7       0.81      0.86      0.83       318\n",
      "           8       0.62      0.68      0.65       304\n",
      "           9       0.64      0.60      0.62       333\n",
      "\n",
      "    accuracy                           0.74      3224\n",
      "   macro avg       0.74      0.74      0.74      3224\n",
      "weighted avg       0.74      0.74      0.74      3224\n",
      "\n",
      "‚úÖ Test Accuracy: 73.70%\n",
      "‚úÖ Validation Accuracy (5-Fold): 75.63%\n"
     ]
    }
   ],
   "source": [
    "import numpy as np\n",
    "import matplotlib.pyplot as plt\n",
    "from sklearn.model_selection import train_test_split, cross_val_score\n",
    "from sklearn.svm import SVC\n",
    "from sklearn.preprocessing import LabelEncoder, StandardScaler\n",
    "from sklearn.metrics import accuracy_score, classification_report\n",
    "from sklearn.multiclass import OneVsRestClassifier\n",
    "from sklearn.utils import shuffle\n",
    "from scipy.stats import kurtosis\n",
    "import torch\n",
    "import torchvision.models as models\n",
    "import torchvision.transforms as transforms\n",
    "from PIL import Image\n",
    "import os\n",
    "import random\n",
    "\n",
    "np.random.seed(42)\n",
    "random.seed(42)\n",
    "torch.manual_seed(42)\n",
    "\n",
    "#subsetting casia b\n",
    "def load_casia_subset(base_path, num_subjects=10, sequences_per_subject=9):\n",
    "    images = []\n",
    "    labels = []\n",
    "\n",
    "    subject_dirs = sorted([d for d in os.listdir(base_path) if os.path.isdir(os.path.join(base_path, d))])\n",
    "    subject_dirs = subject_dirs[:num_subjects]\n",
    "\n",
    "    for subject in subject_dirs:\n",
    "        subject_path = os.path.join(base_path, subject)\n",
    "        for condition in os.listdir(subject_path):\n",
    "            if not condition.startswith(\"nm\"):  #have onlly used normal walking \n",
    "                continue\n",
    "            cond_path = os.path.join(subject_path, condition)\n",
    "            if not os.path.isdir(cond_path):\n",
    "                continue\n",
    "            for angle in os.listdir(cond_path)[:sequences_per_subject]:\n",
    "                angle_path = os.path.join(cond_path, angle)\n",
    "                if not os.path.isdir(angle_path):\n",
    "                    continue\n",
    "                for frame in sorted(os.listdir(angle_path))[:20]: \n",
    "                    frame_path = os.path.join(angle_path, frame)\n",
    "                    try:\n",
    "                        img = Image.open(frame_path).convert(\"RGB\").resize((224, 224))\n",
    "                        images.append(np.array(img) / 255.0)\n",
    "                        labels.append(subject)\n",
    "                    except Exception as e:\n",
    "                        print(f\"Error loading {frame_path}: {e}\")\n",
    "    return np.array(images), np.array(labels)\n",
    "\n",
    "#Feature Extraction using Transfer learning approach (ResNet101)\n",
    "def extract_features_with_resnet(images):\n",
    "    device = torch.device(\"cuda\" if torch.cuda.is_available() else \"cpu\")\n",
    "\n",
    "    resnet = models.resnet101(weights=models.ResNet101_Weights.IMAGENET1K_V1)\n",
    "    resnet.fc = torch.nn.Identity()  # Remove the final classification layer\n",
    "    resnet = resnet.to(device)\n",
    "    resnet.eval()\n",
    "\n",
    "    transform = transforms.Compose([\n",
    "        transforms.ToTensor(),\n",
    "        transforms.Resize((224, 224)),\n",
    "        transforms.Normalize(mean=[0.485, 0.456, 0.406],\n",
    "                             std=[0.229, 0.224, 0.225]),\n",
    "    ])\n",
    "\n",
    "    features = []\n",
    "    with torch.no_grad():\n",
    "        for img in images:\n",
    "            pil_img = Image.fromarray((img * 255).astype(np.uint8))\n",
    "            input_tensor = transform(pil_img).unsqueeze(0).to(device)\n",
    "            feat = resnet(input_tensor)\n",
    "            features.append(feat.cpu().numpy().flatten())\n",
    "    return np.array(features)\n",
    "\n",
    "#Kurtosis-based FS\n",
    "def kurtosis_selection(features, threshold=3):\n",
    "    k_vals = kurtosis(features, axis=0)\n",
    "    selected_features = features[:, k_vals > threshold]\n",
    "    return selected_features\n",
    "\n",
    "#Correlation-based FF\n",
    "def correlation_feature_fusion(features):\n",
    "    corr = np.corrcoef(features.T)\n",
    "    upper_triangle = np.triu(corr, k=1)\n",
    "    fused = np.mean(upper_triangle[upper_triangle != 0])\n",
    "    fused_features = features * fused\n",
    "    return fused_features\n",
    "\n",
    "#OaA SVM Classification\n",
    "def train_svm(features, labels):\n",
    "    # üîÅ Shuffle data\n",
    "    features, labels = shuffle(features, labels)\n",
    "\n",
    "    # ‚öñÔ∏è Standardize\n",
    "    scaler = StandardScaler()\n",
    "    features = scaler.fit_transform(features)\n",
    "\n",
    "    # Split\n",
    "    X_train, X_test, y_train, y_test = train_test_split(features, labels, test_size=0.3)\n",
    "\n",
    "    # Train\n",
    "    model = OneVsRestClassifier(SVC(kernel='linear', probability=True))\n",
    "    model.fit(X_train, y_train)\n",
    "\n",
    "    # Evaluate\n",
    "    y_pred = model.predict(X_test)\n",
    "    test_acc = accuracy_score(y_test, y_pred) * 100\n",
    "    val_scores = cross_val_score(model, features, labels, cv=5)\n",
    "    val_acc = np.mean(val_scores) * 100\n",
    "\n",
    "    print(\"Classification Report:\")\n",
    "    print(classification_report(y_test, y_pred))\n",
    "    print(f\"‚úÖ Test Accuracy: {test_acc:.2f}%\")\n",
    "    print(f\"‚úÖ Validation Accuracy (5-Fold): {val_acc:.2f}%\")\n",
    "\n",
    "#main\n",
    "if __name__ == \"__main__\":\n",
    "    print(\"Loading subset of CASIA-B dataset...\")\n",
    "    casia_path = \"/kaggle/input/casiab\"\n",
    "    data, labels = load_casia_subset(casia_path)\n",
    "\n",
    "    if len(data) == 0:\n",
    "        raise RuntimeError(\"No images loaded. Check dataset path and folder structure.\")\n",
    "\n",
    "    labels = LabelEncoder().fit_transform(labels)\n",
    "\n",
    "    print(\"Extracting deep features using ResNet101...\")\n",
    "    deep_features = extract_features_with_resnet(data)\n",
    "\n",
    "    print(\"Selecting features using kurtosis...\")\n",
    "    selected = kurtosis_selection(deep_features)\n",
    "\n",
    "    print(\"Fusing features using correlation...\")\n",
    "    fused = correlation_feature_fusion(selected)\n",
    "\n",
    "    print(\"Training One-against-All SVM...\")\n",
    "    train_svm(fused, labels)\n"
   ]
  }
 ],
 "metadata": {
  "kaggle": {
   "accelerator": "none",
   "dataSources": [
    {
     "datasetId": 2125243,
     "sourceId": 3533193,
     "sourceType": "datasetVersion"
    }
   ],
   "dockerImageVersionId": 31012,
   "isGpuEnabled": false,
   "isInternetEnabled": true,
   "language": "python",
   "sourceType": "notebook"
  },
  "kernelspec": {
   "display_name": "Python 3",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.11.11"
  },
  "papermill": {
   "default_parameters": {},
   "duration": 7586.176031,
   "end_time": "2025-04-27T02:59:04.261315",
   "environment_variables": {},
   "exception": null,
   "input_path": "__notebook__.ipynb",
   "output_path": "__notebook__.ipynb",
   "parameters": {},
   "start_time": "2025-04-27T00:52:38.085284",
   "version": "2.6.0"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 5
}
